{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d37a6bc0",
      "metadata": {
        "id": "d37a6bc0"
      },
      "source": [
        "# Assignment 1 - Binary Classification Evaluation Metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1679a82",
      "metadata": {
        "id": "d1679a82"
      },
      "source": [
        "**Objective:**\n",
        "The objective of this assignment is to assess your understanding of fundamental concepts in model evaluation for machine learning tasks. This assignment covers topics discussed in the first half of the course, including key evaluation metrics, confusion matrices, ROC curves, and Precision-Recall curves.\n",
        "Instructions:\n",
        "\n",
        "1. Theory Questions:\n",
        "Answer the following theoretical questions:\n",
        "\n",
        "    1. Explain the limitations of accuracy as an evaluation metric in imbalanced datasets. How does accuracy behave when classes are heavily skewed, and why might it provide misleading results?\n",
        "    2. Describe the purpose and interpretation of a confusion matrix. How does it help in assessing a classification model's performance?\n",
        "    3. Explain the concept of ROC curves. What does each point on an ROC curve represent? How is the area under the ROC curve (AUC-ROC) calculated?\n",
        "    4. Compare and contrast the advantages and disadvantages of ROC curves and Precision-Recall curves. In what scenarios would you prefer to use one over the other, and why?\n",
        "\n",
        "2. Practical Exercises:\n",
        "* Implement Python code to calculate the following evaluation metrics for a given binary classification problem: Log Loss\n",
        "* Select the best metric for an applied scenario\n",
        "\n",
        "**Submission Guidelines:**\n",
        "* Submit your responses to the theory questions in a neatly organized markdown.\n",
        "* Include your Python code for the practical exercise.\n",
        "* Submit your assignment as a single `.ipynb` file named `MY NAME Assignment 1 - Log Loss` via the course submission platform (slack)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e58864fe",
      "metadata": {
        "id": "e58864fe"
      },
      "source": [
        "## Part 1: Theory Questions (20 points)\n",
        "Provide your answers here:\n",
        "\n",
        "    1. Accuracy as an evaluation metric in imbalanced datasets can make a model appear as if it performing better than it really is for the given task. For example, if building a model to detect fraud (noted as the positive class), and fraud is a rare occurence (1 out of every 100), if the model were to always predict the negative class the accuracy would still show as .99 even though it is doing a poor job at the task given.\n",
        "    2. A confusion matrix is a 2x2 table that lists True Positives, True Negatives, False Positives, and False Negatives. Confusion matrices can help visually identify where a binary classification model is missing the mark, and can also help with quick calculation of key metrics such as Precision and Recall.\n",
        "    3. A ROC is a representation of performance of a classification model across thresholds. It plots the True Positive Rate against the False Positive rate. Eeach poin ton a ROC curve representes the True Positive rate and False Positive rate across every threshold value. ROC-AUC is calculated by summing the total area under the plotted curve. 1 represents a perfect classifier and 0.5 represents a completely random classifier.\n",
        "    4. ROC is vest used when working with balanced datasets, where PR curves are best used when dealing with imbalanced datasets. PR curves would be better used in a scenario such as medical diagnosis where identifying positive instances is important."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b8c2adb",
      "metadata": {
        "id": "8b8c2adb"
      },
      "source": [
        "## Practicing Log Loss (25 Points)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f4dca41",
      "metadata": {
        "id": "2f4dca41"
      },
      "source": [
        "**Objective:**\n",
        "The objective of this assignment is to deepen your understanding of log loss, also known as logarithmic loss or cross-entropy loss, and its application in evaluating the performance of classification models.\n",
        "\n",
        "**Instructions:**\n",
        "In this assignment, you will be given a set of binary classification predictions along with their corresponding actual class labels. Your task is to calculate the log loss for each prediction and then analyze the overall log loss performance of the model.\n",
        "\n",
        "**Dataset:**\n",
        "You are provided with a dataset containing the following information:\n",
        "\n",
        "Predicted probabilities for the positive class (ranging from 0 to 1) for a set of instances.\n",
        "Actual binary class labels (0 or 1) indicating whether the instance belongs to the positive class or not.\n",
        "\n",
        "**Assignment Tasks:**\n",
        "1. Calculate the log loss for each instance in the dataset using the predicted probabilities and actual class labels.\n",
        "2. Summarize the individual log losses and compute the overall log loss performance for the model.\n",
        "3. Interpret the overall log loss value and analyze the model's performance. Discuss any insights or observations derived from the log loss analysis.\n",
        "\n",
        "\n",
        "**Dataset:**\n",
        "\n",
        "| Instance | Predicted Probability | Actual Label |\n",
        "|----------|------------------------|--------------|\n",
        "|    1     |          0.9           |       1      |\n",
        "|    2     |          0.3           |       0      |\n",
        "|    3     |          0.6           |       1      |\n",
        "|    4     |          0.8           |       0      |\n",
        "|    5     |          0.1           |       1      |\n",
        "\n",
        "\n",
        "**Grading Criteria:**\n",
        "\n",
        "* Correctness of log loss calculations.\n",
        "* Clarity and completeness of the analysis.\n",
        "* Insights derived from the log loss interpretation.\n",
        "* Overall presentation and adherence to submission guidelines."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "3dad6832",
      "metadata": {
        "id": "3dad6832",
        "outputId": "871cfb8d-33ad-4e34-a4a0-6ae44dccc743",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Instance  Predicted Probability  Actual Label\n",
            "0         1                    0.9             1\n",
            "1         2                    0.3             0\n",
            "2         3                    0.6             1\n",
            "3         4                    0.8             0\n",
            "4         5                    0.1             1\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a DataFrame with the dataset\n",
        "data = {\n",
        "    'Instance': [1, 2, 3, 4, 5],\n",
        "    'Predicted Probability': [0.9, 0.3, 0.6, 0.8, 0.1],\n",
        "    'Actual Label': [1, 0, 1, 0, 1]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Display the DataFrame\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "9be2a3c3",
      "metadata": {
        "id": "9be2a3c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be7e3bcd-2c17-4a90-fc5c-c63d1b95d4b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Instance  Predicted Probability  Actual Label  Log Loss\n",
            "0         1                    0.9             1  0.105361\n",
            "1         2                    0.3             0  0.356675\n",
            "2         3                    0.6             1  0.510826\n",
            "3         4                    0.8             0  1.609438\n",
            "4         5                    0.1             1  2.302585\n",
            "Summarized Log Loss:  0.98\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# 1) Calculate the log loss for each instance in the dataset using the predicted probabilities and actual class labels.\n",
        "def log_loss(y_true, y_pred):\n",
        "    loss = - (y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
        "    return loss\n",
        "\n",
        "df['Log Loss'] = log_loss(df['Actual Label'], df['Predicted Probability'])\n",
        "\n",
        "print(df)\n",
        "\n",
        "# 2) Summarize the individual log losses and compute the overall log loss performance for the model.\n",
        "print(f\"Summarized Log Loss: {np.average(df['Log Loss']): .2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eaa92db1",
      "metadata": {
        "id": "eaa92db1"
      },
      "source": [
        "*Question: Interpret the log loss above. How would it change if the predicted probability for instance 0 changed from 0.9 to 0.6? Why?*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2abec414",
      "metadata": {
        "id": "2abec414"
      },
      "source": [
        "*Your answer:* With Log Loss ranging from 0 to infiity, the Log Loss of 0.98 means that the model is doing a reasonable good job at prediction, although it could improve still. Changing instance 0 from 0.9 to 0.6 would increase the log loss meaning model performance would be worse. Since our Actual Label is 1 and we are predicted probability is moving way from 1 we know that our Log Loss will increase."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "972c7485",
      "metadata": {
        "id": "972c7485"
      },
      "source": [
        "*Question: Why might you select log loss over precision, recall, or accuracy (in the context of any problem, not this one specifically)?*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88b26ee2",
      "metadata": {
        "id": "88b26ee2"
      },
      "source": [
        "*Your answer:* Overall log loss compared to other evaluation metrics helps us get some measure of the confidence in our predictions. Meaning that when we have a higher log loss value that our model was more confidently incorrect. This also means that log loss doesn't take into consideration a threshold value when doing evaluation."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a69ed6d7",
      "metadata": {
        "id": "a69ed6d7"
      },
      "source": [
        "## Application Scenario: Select a Metric (55 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "791158c2",
      "metadata": {
        "id": "791158c2"
      },
      "source": [
        "**Application Scenario: Fraud Detection System**\n",
        "\n",
        "You are working as a data scientist for a financial institution that wants to develop a fraud detection system to identify potentially fraudulent transactions. The dataset contains information about various transactions, including transaction amount, merchant ID, and transaction type. Your task is to build a machine learning model to classify transactions as either fraudulent or non-fraudulent.\n",
        "\n",
        "**Problem Description:**\n",
        "\n",
        "* Dataset: The dataset consists of historical transaction data, with labels indicating whether each transaction was fraudulent or not.\n",
        "* Class Distribution: The dataset is mostly non-fraudulant cases, with a small percentage of transactions being fraudulent compared to legitimate transactions.\n",
        "* Objective: The objective is to develop a fraud detection model that minimizes false negatives (fraudulent transactions incorrectly classified as non-fraudulent) while maintaining a reasonable level of precision.\n",
        "\n",
        "**Stakeholder Requirements:**\n",
        "Given the nature of the problem, it is crucial to prioritize recall (sensitivity) to ensure that as many fraudulent transactions as possible are detected. However, precision is also important to minimize false positives and avoid unnecessary investigations of legitimate transactions. Minimizing false negatives (missing fraudulent transactions) is of utmost importance.\n",
        "\n",
        "**Task:**\n",
        "Your task is to develop Python code to evaluate the performance of different machine learning models using various evaluation metrics, including accuracy, precision, recall, and F2 score. *Select the evaluation metric that best suits the problem and explain your choice*.\n",
        "\n",
        "**Additional Guidelines:**\n",
        "* You should preprocess the dataset as needed and split it into training and testing sets.\n",
        "* Implement machine learning models of your choice (e.g., logistic regression, random forest) and evaluate their performance.\n",
        "* Use appropriate evaluation metrics for binary classification tasks.\n",
        "* Discuss the rationale behind your choice of evaluation metric and how it aligns with the problem requirements.\n",
        "* Present your findings and recommendations for selecting the best model based on the chosen evaluation metric."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc4f0e46",
      "metadata": {
        "id": "dc4f0e46"
      },
      "source": [
        "**Dataset Sample:**\n",
        "\n",
        "| Transaction ID | Transaction Amount | Merchant ID | Transaction Type | Fraudulent |\n",
        "|----------------|--------------------|-------------|------------------|------------|\n",
        "| 1              | 1000               | M123        | Online Purchase  | 0          |\n",
        "| 2              | 500                | M456        | ATM Withdrawal   | 0          |\n",
        "| 3              | 2000               | M789        | Online Purchase  | 1          |\n",
        "| 4              | 1500               | M123        | POS Transaction  | 0          |\n",
        "| 5              | 800                | M456        | Online Purchase  | 0          |\n",
        "| 6              | 3000               | M789        | ATM Withdrawal   | 1          |\n",
        "\n",
        "* Transaction ID: Unique identifier for each transaction.\n",
        "* Transaction Amount: The amount of money involved in the transaction.\n",
        "* Merchant ID: Identifier for the merchant involved in the transaction.\n",
        "* Transaction Type: The type of transaction (e.g., online purchase, ATM withdrawal, POS transaction).\n",
        "* Fraudulent: Binary indicator (0 or 1) specifying whether the transaction is fraudulent (1) or not (0)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "1bc1ec81",
      "metadata": {
        "id": "1bc1ec81",
        "outputId": "d0bb2ba9-415b-41fa-c0db-ba58ba13c777",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Transaction ID  Transaction Amount Merchant ID Transaction Type  \\\n",
            "0                1                1000        M123  Online Purchase   \n",
            "1                2                 500        M456   ATM Withdrawal   \n",
            "2                3                2000        M789  Online Purchase   \n",
            "3                4                1500        M123  POS Transaction   \n",
            "4                5                 800        M456  Online Purchase   \n",
            "5                6                3000        M789   ATM Withdrawal   \n",
            "6                7                1200        M123  Online Purchase   \n",
            "7                8                 700        M456   ATM Withdrawal   \n",
            "8                9                1800        M789  Online Purchase   \n",
            "9               10                1300        M123  POS Transaction   \n",
            "10              11                 900        M456  Online Purchase   \n",
            "11              12                 400        M789   ATM Withdrawal   \n",
            "12              13                2200        M123  Online Purchase   \n",
            "13              14                1600        M456   ATM Withdrawal   \n",
            "14              15                 850        M789  Online Purchase   \n",
            "15              16                2800        M123  POS Transaction   \n",
            "16              17                1100        M456  Online Purchase   \n",
            "17              18                 600        M789   ATM Withdrawal   \n",
            "18              19                1900        M123  Online Purchase   \n",
            "19              20                1400        M456   ATM Withdrawal   \n",
            "20              21                 950        M123  Online Purchase   \n",
            "21              22                 300        M456   ATM Withdrawal   \n",
            "22              23                2100        M789  Online Purchase   \n",
            "23              24                1700        M123  POS Transaction   \n",
            "24              25                 820        M456  Online Purchase   \n",
            "25              26                3200        M789   ATM Withdrawal   \n",
            "26              27                1250        M123  Online Purchase   \n",
            "27              28                 720        M456   ATM Withdrawal   \n",
            "28              29                1850        M789  Online Purchase   \n",
            "29              30                1350        M123  POS Transaction   \n",
            "30              31                 880        M456  Online Purchase   \n",
            "31              32                 420        M789   ATM Withdrawal   \n",
            "32              33                2400        M123  Online Purchase   \n",
            "33              34                1750        M456   ATM Withdrawal   \n",
            "34              35                 830        M789  Online Purchase   \n",
            "35              36                3100        M123  POS Transaction   \n",
            "36              37                1150        M456  Online Purchase   \n",
            "37              38                 620        M789   ATM Withdrawal   \n",
            "38              39                1950        M123  Online Purchase   \n",
            "39              40                1450        M456   ATM Withdrawal   \n",
            "\n",
            "    Fraudulent  \n",
            "0            0  \n",
            "1            0  \n",
            "2            1  \n",
            "3            0  \n",
            "4            0  \n",
            "5            1  \n",
            "6            0  \n",
            "7            0  \n",
            "8            1  \n",
            "9            0  \n",
            "10           0  \n",
            "11           1  \n",
            "12           0  \n",
            "13           0  \n",
            "14           1  \n",
            "15           0  \n",
            "16           0  \n",
            "17           1  \n",
            "18           0  \n",
            "19           0  \n",
            "20           1  \n",
            "21           0  \n",
            "22           0  \n",
            "23           1  \n",
            "24           0  \n",
            "25           0  \n",
            "26           1  \n",
            "27           0  \n",
            "28           0  \n",
            "29           1  \n",
            "30           0  \n",
            "31           0  \n",
            "32           1  \n",
            "33           0  \n",
            "34           0  \n",
            "35           1  \n",
            "36           0  \n",
            "37           0  \n",
            "38           1  \n",
            "39           0  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Creating the dataset\n",
        "data = {\n",
        "    'Transaction ID': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10,\n",
        "                       11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n",
        "                       21, 22, 23, 24, 25, 26, 27, 28, 29, 30,\n",
        "                       31, 32, 33, 34, 35, 36, 37, 38, 39, 40],\n",
        "    'Transaction Amount': [1000, 500, 2000, 1500, 800, 3000, 1200, 700, 1800, 1300,\n",
        "                           900, 400, 2200, 1600, 850, 2800, 1100, 600, 1900, 1400,\n",
        "                           950, 300, 2100, 1700, 820, 3200, 1250, 720, 1850, 1350,\n",
        "                           880, 420, 2400, 1750, 830, 3100, 1150, 620, 1950, 1450],\n",
        "    'Merchant ID': ['M123', 'M456', 'M789', 'M123', 'M456', 'M789', 'M123', 'M456', 'M789', 'M123',\n",
        "                    'M456', 'M789', 'M123', 'M456', 'M789', 'M123', 'M456', 'M789', 'M123', 'M456',\n",
        "                    'M123', 'M456', 'M789', 'M123', 'M456', 'M789', 'M123', 'M456', 'M789', 'M123',\n",
        "                    'M456', 'M789', 'M123', 'M456', 'M789', 'M123', 'M456', 'M789', 'M123', 'M456'],\n",
        "    'Transaction Type': ['Online Purchase', 'ATM Withdrawal', 'Online Purchase', 'POS Transaction', 'Online Purchase',\n",
        "                         'ATM Withdrawal', 'Online Purchase', 'ATM Withdrawal', 'Online Purchase', 'POS Transaction',\n",
        "                         'Online Purchase', 'ATM Withdrawal', 'Online Purchase', 'ATM Withdrawal', 'Online Purchase',\n",
        "                         'POS Transaction', 'Online Purchase', 'ATM Withdrawal', 'Online Purchase', 'ATM Withdrawal',\n",
        "                         'Online Purchase', 'ATM Withdrawal', 'Online Purchase', 'POS Transaction', 'Online Purchase',\n",
        "                         'ATM Withdrawal', 'Online Purchase', 'ATM Withdrawal', 'Online Purchase', 'POS Transaction',\n",
        "                         'Online Purchase', 'ATM Withdrawal', 'Online Purchase', 'ATM Withdrawal', 'Online Purchase',\n",
        "                         'POS Transaction', 'Online Purchase', 'ATM Withdrawal', 'Online Purchase', 'ATM Withdrawal'],\n",
        "    'Fraudulent': [0, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n",
        "                   0, 1, 0, 0, 1, 0, 0, 1, 0, 0,\n",
        "                   1, 0, 0, 1, 0, 0, 1, 0, 0, 1,\n",
        "                   0, 0, 1, 0, 0, 1, 0, 0, 1, 0]\n",
        "}\n",
        "\n",
        "# Creating DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Displaying the DataFrame\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split into Train/Validate/Test and use Pipeline and ColumnTranformer to Preprocess Data"
      ],
      "metadata": {
        "id": "H04MVnTip1q2"
      },
      "id": "H04MVnTip1q2"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "4eb158cb",
      "metadata": {
        "id": "4eb158cb"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Split into X and Y\n",
        "X = df.iloc[:, [1, 2, 3]]\n",
        "y = df.iloc[:, 4]\n",
        "\n",
        "# Train-Test Split\n",
        "## Split into Training and Test/Validation Set\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "## Split Test/Validation into Test and Validation Sets\n",
        "X_validate, X_test, y_validate, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Build Preprocessing Pipeline\n",
        "numeric_list = ['Transaction Amount']\n",
        "\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy=\"mean\")),\n",
        "    ('scaler', MinMaxScaler())\n",
        "])\n",
        "\n",
        "category_list = ['Merchant ID', 'Transaction Type']\n",
        "\n",
        "for col in category_list:\n",
        "    X_train[col] = X_train[col].astype('category')\n",
        "    X_validate[col] = X_validate[col].astype('category')\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value=\"MISSING\")),\n",
        "    ('onehot', OneHotEncoder(sparse_output=False, handle_unknown='infrequent_if_exist'))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_list),\n",
        "        ('cat', categorical_transformer, category_list)\n",
        "    ],\n",
        "    remainder='passthrough'\n",
        ")\n",
        "\n",
        "processed_train = preprocessor.fit_transform(X_train)\n",
        "processed_validate = preprocessor.transform(X_validate)\n",
        "processed_test = preprocessor.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use Grid Search to find best Hyperparameters for the chosen models"
      ],
      "metadata": {
        "id": "pvVfKMzTqF8V"
      },
      "id": "pvVfKMzTqF8V"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import make_scorer, fbeta_score\n",
        "\n",
        "rfc = RandomForestClassifier(random_state=42)\n",
        "rfc_params = {\n",
        "    'n_estimators': [10, 100, 500],\n",
        "    'min_samples_split': [2, 5, 20],\n",
        "    'max_depth': [None, 5, 20]\n",
        "}\n",
        "\n",
        "lr = LogisticRegression(random_state=42)\n",
        "lr_params = {\n",
        "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'solver': ['liblinear', 'saga']\n",
        "}\n",
        "\n",
        "models = {\n",
        "    'Random Forest': (rfc, rfc_params),\n",
        "    'Logistic Regression': (lr, lr_params)\n",
        "}\n",
        "\n",
        "## Use Make Scorer to create an F2 Score - I chose F2 as it more heavily weights recall which is what we care about the most, but we also do still consider precision.\n",
        "f2_scorer = make_scorer(fbeta_score, beta=2)\n",
        "\n",
        "# Apply GridSearch to Random Forest and Print Results\n",
        "grid_search_rf = GridSearchCV(rfc, rfc_params, cv=5, scoring=f2_scorer)\n",
        "grid_search_rf.fit(processed_train, y_train)\n",
        "\n",
        "best_score_rf = grid_search_rf.best_score_\n",
        "best_model_rf = grid_search_rf.best_estimator_\n",
        "best_params_rf = grid_search_rf.best_params_\n",
        "\n",
        "validate_score_rf = best_model_rf.score(processed_validate, y_validate)\n",
        "\n",
        "print(f\"Model: Random Forest\")\n",
        "print(f\"Best Parameters: {best_params_rf}\")\n",
        "print(f\"Best Cross Validation Score: {best_score_rf}\")\n",
        "print(f\"Validate Score with Best Model: {validate_score_rf}\")\n",
        "\n",
        "# Apply GridSearch to Logistic Regression and Print Results\n",
        "grid_search_lr = GridSearchCV(lr, lr_params, cv=5, scoring=f2_scorer)\n",
        "grid_search_lr.fit(processed_train, y_train)\n",
        "\n",
        "best_score_lr = grid_search_lr.best_score_\n",
        "best_model_lr = grid_search_lr.best_estimator_\n",
        "best_params_lr = grid_search_lr.best_params_\n",
        "\n",
        "validate_score_lr = best_model_lr.score(processed_validate, y_validate)\n",
        "\n",
        "print(f\"Model: Logistic Regression\")\n",
        "print(f\"Best Parameters: {best_params_lr}\")\n",
        "print(f\"Best Cross Validation Score: {best_score_lr}\")\n",
        "print(f\"Validate Score with Best Model: {validate_score_lr}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWoCyoE4j2Fs",
        "outputId": "443efeca-9368-45ab-dd16-7663a6b285b1"
      },
      "id": "LWoCyoE4j2Fs",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: Random Forest\n",
            "Best Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 10}\n",
            "Best Cross Validation Score: 0.5871794871794871\n",
            "Validate Score with Best Model: 0.25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: Logistic Regression\n",
            "Best Parameters: {'C': 100, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "Best Cross Validation Score: 0.4479638009049774\n",
            "Validate Score with Best Model: 0.25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use Random Forest on Test Set\n",
        "Both models had the same validate score based on F2, but the Random Forest had a higher Cross Validation Score so that's the model that I've chosen to use against test. Overall both model's performance was very low.\n",
        "\n",
        "If this were a real-life example, I'd probably stop at this point and look to other models, or adjusting hyperparameters further. Overall there are only four items to predict against within the validation set, so this low number of observations can highly skew our results."
      ],
      "metadata": {
        "id": "6mVsZwFFpHAy"
      },
      "id": "6mVsZwFFpHAy"
    },
    {
      "cell_type": "code",
      "source": [
        "test_score = best_model_rf.score(processed_test, y_test)\n",
        "print(f\"Score of Random Forest on Test Set: {test_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AW6p-w27nxVX",
        "outputId": "55320d43-6933-4fa1-feb6-fa647e291991"
      },
      "id": "AW6p-w27nxVX",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score of Random Forest on Test Set: 0.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Confusion Matrix to Display Results on Test Set"
      ],
      "metadata": {
        "id": "45GI_94srHD2"
      },
      "id": "45GI_94srHD2"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "y_pred = best_model_rf.predict(processed_test)\n",
        "\n",
        "results = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
        "print(results)\n",
        "print(\"\")\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "# Swapping rows and columns to get True Positives in the top-left\n",
        "cm_rearranged = np.array([[cm[1, 1], cm[1, 0]],\n",
        "                          [cm[0, 1], cm[0, 0]]])\n",
        "\n",
        "print(\"Rearranged Confusion Matrix:\\n\", cm_rearranged)\n",
        "\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm_rearranged)\n",
        "disp.plot(cmap='Blues')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "id": "17uym_BcqZCS",
        "outputId": "e45e051e-bedb-4e09-e54e-f98aa2684b7b"
      },
      "id": "17uym_BcqZCS",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Actual  Predicted\n",
            "16       0          0\n",
            "12       0          1\n",
            "19       0          0\n",
            "27       0          0\n",
            "\n",
            "Rearranged Confusion Matrix:\n",
            " [[0 0]\n",
            " [1 3]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x79ddd184f940>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}